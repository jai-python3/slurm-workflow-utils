{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Slurm Workflow Utils","text":"<p>Collection of Python scripts to facilitate creation and dispatching of computational jobs via SLURM sbatch scripts.</p>"},{"location":"#commands","title":"Commands","text":"<p>To following exported console scripts are available:</p> <ul> <li>workflow-builder</li> <li>workflow-launcher</li> </ul>"},{"location":"#references","title":"References","text":"<ul> <li>GitHub</li> <li>PYPI</li> </ul>"},{"location":"CHANGELOG/","title":"CHANGELOG","text":""},{"location":"CHANGELOG/#v010-2024-02-01","title":"v0.1.0 - 2024-02-01","text":"<p>ADDS: - workflow-builder - workflow-launcher</p>"},{"location":"INSTALL/","title":"INSTALL","text":""},{"location":"INSTALL/#install-from-pypi","title":"Install from PYPI","text":"<p>Install the package in your Python virtual environment</p> <pre><code>source venv/bin/activate\npip install slurm-workflow-utils\n</code></pre>"},{"location":"INSTALL/#clone-project","title":"Clone project","text":"<p>You can <code>git clone</code> this project.</p> <pre><code>git clone https://github.com/jai-python3/slurm-workflow-utils.git\ncd slurm-workflow-utils\n</code></pre>"},{"location":"INSTALL/#local-pip-install","title":"Local pip install","text":"<p>You can optionally establish a Python virtual environment. Then you can run the <code>setup.py</code> script to build to project and then run <code>pip install</code> to install in your local Python virtual environment.</p> <pre><code>virtualenv -p python3 venv\nsource venv/bin/activate\npython setup.py sdist\npip install .\n</code></pre>"},{"location":"INSTALL/#uninstall","title":"Uninstall","text":"<p>You can uninstall like this:</p> <pre><code>source venv/bin/activate\npip uninstall slurm-workflow-utils\nmake clean\n</code></pre>"},{"location":"INSTALL/#developers","title":"Developers","text":"<p>If you modify the code in this package in your local virtual environment:</p> <pre><code>pip uninstall slurm-workflow-utils\nmake clean\npython setup.py sdist\npip install .\n</code></pre>"},{"location":"INSTALL/#publish-to-pypi","title":"Publish to PYPI","text":"<p>You want can publish the code in this package to the PYPI repository.</p>"},{"location":"INSTALL/#install-twine-and-setuptools","title":"Install twine and setuptools","text":"<p>Install <code>twine</code> and <code>setuptools</code>.</p> <pre><code>pip install twine setuptools\n</code></pre>"},{"location":"INSTALL/#build-the-distribution-package","title":"Build the Distribution Package","text":"<pre><code>python setup.py sdist bdist_wheel\n</code></pre>"},{"location":"INSTALL/#configure-your-pypirc","title":"Configure your ~/.pypirc:","text":"<pre><code>[pypi]\n  username = __token__\n  password = pypi-YOUR-TOKEN\n</code></pre>"},{"location":"INSTALL/#upload-your-package-to-pypi","title":"Upload Your Package to PyPI","text":"<pre><code>twine upload dist/*\n</code></pre>"},{"location":"TODO/","title":"TODO","text":"<ul> <li>Implement unit tests (pytest)</li> <li>Add Use Case diagram</li> <li>Add Class diagram</li> </ul>"},{"location":"builder/","title":"Builder module","text":""},{"location":"builder/#slurm_workflow_utils.builder.Builder","title":"<code>Builder</code>","text":"<p>Class for build all of the SLURM shell scripts to orchestrate a workflow.</p> Source code in <code>slurm_workflow_utils/builder.py</code> <pre><code>class Builder:\n    \"\"\"Class for build all of the SLURM shell scripts to orchestrate a workflow.\"\"\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Constructor for Builder.\"\"\"\n        self.control_file = kwargs.get(\"control_file\", None)\n        self.logfile = kwargs.get(\"logfile\", None)\n        self.outdir = kwargs.get(\"outdir\", None)\n        self.verbose = kwargs.get(\"verbose\", constants.DEFAULT_VERBOSE)\n\n        logging.info(f\"Will load contents of config file '{self.control_file}'\")\n        # self.control_lookup = yaml.safe_load(Path(self.control_file).read_text())\n        with open(self.control_file, \"r\") as file:\n            self.control_lookup = yaml.load(file, Loader=SafeLoader)\n\n        logging.info(f\"Instantiated Builder in file '{os.path.abspath(__file__)}'\")\n\n    def build(self) -&gt; None:\n\n        if \"job_sets\" not in self.control_lookup:\n            raise ValueError(f\"'job_sets' was not found in control file '{self.control_file}'\")\n        job_sets_lookup = self.control_lookup[\"job_sets\"]\n\n        if \"workflow\" not in self.control_lookup:\n            raise ValueError(f\"'workflow' was not found in control file '{self.control_file}'\")\n\n        if \"common\" not in self.control_lookup[\"workflow\"]:\n            raise ValueError(f\"'common' was not found in control file '{self.control_file}'\")\n        common_lookup = self.control_lookup[\"workflow\"][\"common\"]\n\n        if \"%KEY%\" not in common_lookup:\n            raise ValueError(f\"'%KEY%' was not found in common_lookup '{common_lookup}'\")\n        key_placeholder = common_lookup[\"%KEY%\"]\n\n        if \"definitions\" not in self.control_lookup[\"workflow\"]:\n            raise ValueError(f\"'definitions' was not found in control file '{self.control_file}'\")\n        definitions_lookup = self.control_lookup[\"workflow\"][\"definitions\"]\n\n        template_file = None\n        if \"template_file\" in self.control_lookup[\"workflow\"][\"common\"]:\n            template_file = self.control_lookup[\"workflow\"][\"common\"][\"template_file\"]\n        else:\n            logging.info(f\"template_file was not defined in the [workflow][common] section of the control file '{self.control_file}'\")\n\n        if common_lookup[\"%TIMESTAMP%\"] is None or common_lookup[\"%TIMESTAMP%\"] == \"\":\n            common_lookup[\"%TIMESTAMP%\"] = constants.DEFAULT_TIMESTAMP\n            logging.info(f\"%TIMESTAMP% was not specified and therefore was set to '{constants.DEFAULT_TIMESTAMP}'\")\n\n        sbatch_script_list = []\n\n        # Process each job set.\n        for subflow_ctr, job_set in enumerate(job_sets_lookup, start=1):\n            logging.info(f\"job_set: {job_set}\")\n\n            if key_placeholder not in job_set:\n                raise ValueError(f\"key_placeholder '{key_placeholder}' was not found in job_set '{job_set}'\")\n            key = job_set[key_placeholder]\n\n            job_lookup = job_set\n            job_lookup.update(common_lookup)\n\n            previous_job_name = None\n\n            subflow_symlink_name = self._create_subflow_directory(f\"{common_lookup['%JOB_SET_OUTDIR%']}/{common_lookup['%TIMESTAMP%']}/{key}\", subflow_ctr)\n\n            # Process each job definition.\n            for job_ctr, job_definition in enumerate(definitions_lookup, start=1):\n                step_number = f\"step-{job_ctr}\"\n                logging.info(f\"Processing step '{step_number}' job_definition: {job_definition}\")\n\n                if \"template_file\" not in job_definition or job_definition[\"template_file\"] is None or job_definition == \"\":\n                    if template_file is None:\n                        raise ValueError(f\"job_definition['template_file'] was not defined for job with name '{job_definition['%JOB_NAME%']}'\")\n                    job_definition[\"template_file\"] = template_file\n                    logging.info(f\"job_definition['template_file'] was not defined and therefore was set to common template file '{template_file}'\")\n\n                if job_ctr == 1:\n                    job_definition[\"%DEPENDENCY%\"] = \"\"\n                else:\n                    if previous_job_name is None or previous_job_name == \"\":\n                        raise ValueError(f\"previous_job_name was not defined while processing job with name '{job_definition['%JOB_NAME%']}'\")\n\n                    job_definition[\"%DEPENDENCY%\"] = f\"#SBATCH --dependency=afterok:{previous_job_name}\"\n\n                if \"%STDOUT%\" not in job_definition:\n                    job_definition[\"%STDOUT%\"] = f\"{common_lookup['%JOB_SET_OUTDIR%']}/{common_lookup['%TIMESTAMP%']}/{key}/{job_definition['%JOB_NAME%']}/{job_definition['%JOB_NAME%']}.stdout\"\n\n                if \"%STDERR%\" not in job_definition:\n                    job_definition[\"%STDERR%\"] = f\"{common_lookup['%JOB_SET_OUTDIR%']}/{common_lookup['%TIMESTAMP%']}/{key}/{job_definition['%JOB_NAME%']}/{job_definition['%JOB_NAME%']}.stderr\"\n\n                job_lookup.update(job_definition)\n                # print(f\"{job_lookup=}\")\n                # sys.exit(1)\n\n                self._perform_inplace_substitutions(job_lookup)\n\n                job_file = os.path.join(\n                    # self.outdir,\n                    common_lookup['%JOB_SET_OUTDIR%'],\n                    common_lookup['%TIMESTAMP%'],\n                    key,\n                    job_lookup['%JOB_NAME%'],\n                    f\"{job_lookup['%JOB_NAME%']}.yaml\"\n                )\n\n                job_symlink_name = self._create_job_directory(job_file, job_ctr)\n\n                logging.info(f\"{job_file=}\")\n                logging.info(f\"{job_lookup=}\")\n                # sys.exit(1)\n\n\n                self._write_job_lookup_to_file(job_lookup, job_file)\n\n                outfile = os.path.join(\n                    # self.outdir,\n                    common_lookup['%JOB_SET_OUTDIR%'],\n                    common_lookup['%TIMESTAMP%'],\n                    key,\n                    job_lookup['%JOB_NAME%'],\n                    f\"{job_lookup['%JOB_NAME%']}.sbatch.sh\"\n                )\n\n\n                self._write_job_lookup_to_file(job_lookup, job_file)\n                logging.info(f\"{job_file=} {template_file=} {outfile=}\")\n\n                manager = TemplateToolkitManager(\n                    verbose=self.verbose\n                )\n\n                manager.make_substitutions(#job_file, template_file, outfile)\n                    key_val_file=job_file,\n                    template_file=template_file,\n                    outfile=outfile,\n                )\n\n                sbatch_script_list.append(outfile)\n\n                previous_job_name = job_lookup[\"%JOB_NAME%\"]\n                logging.info(f\"Set previous_job_name to '{previous_job_name}'\")\n\n        self._write_sbatch_script_list_to_file(\n            sbatch_script_list,\n            f\"{common_lookup['%JOB_SET_OUTDIR%']}/{common_lookup['%TIMESTAMP%']}\"\n        )\n\n    def _write_sbatch_script_list_to_file(self, sbatch_script_list: List[str], outdir: str) -&gt; None:\n        \"\"\"Write the sbatch script list to a file.\n\n        Args:\n            sbatch_script_list (List[str]): The sbatch script list.\n            outdir (str): The output directory.\n        \"\"\"\n        outfile = os.path.join(outdir, \"sbatch_scripts.txt\")\n        with open(outfile, \"w\") as of:\n            of.write(f\"## method-created: {os.path.abspath(__file__)}\\n\")\n            of.write(f\"## date-created: {str(datetime.today().strftime('%Y-%m-%d-%H%M%S'))}\\n\")\n            of.write(f\"## created-by: {os.environ.get('USER')}\\n\")\n            of.write(f\"## control-file: {self.control_file}\\n\")\n            of.write(f\"## logfile: {self.logfile}\\n\")\n\n            for sbatch_script in sbatch_script_list:\n                of.write(f\"{sbatch_script}\\n\")\n\n        if self.verbose:\n            console.log(f\"Wrote sbatch script list to file '{outfile}'\")\n        logging.info(f\"Wrote sbatch script list to file '{outfile}'\")\n\n    def _perform_inplace_substitutions(self, lookup: Dict[str, Any]) -&gt; None:\n        \"\"\"Perform the placeholder substitutions among the values in the job definition lookup.\n\n        Args:\n            lookup (Dict[str, Any]): The job definition lookup.\n        \"\"\"\n        for _ in range(3):\n            for key in lookup:\n                for current_key, val in lookup.items():\n                    if key == current_key:\n                        continue\n                    # print(f\"{key=} {current_key=} {val=}\")\n                    if key in val:\n                        lookup[current_key] = val.replace(key, lookup[key])\n\n\n    def _write_job_lookup_to_file(self, job_lookup: Dict[str, Any], job_file: str) -&gt; None:\n        \"\"\"Write the job lookup to a file.\n\n        Args:\n            job_file (str): The output job file.\n            job_lookup (Dict[str, Any]): The job lookup.\n        \"\"\"\n        dirname = os.path.dirname(job_file)\n        if not os.path.exists(dirname):\n            pathlib.Path(dirname).mkdir(parents=True, exist_ok=True)\n            logging.info(f\"Created directory '{dirname}'\")\n\n        with open(job_file, \"w\") as file:\n            yaml.dump(dict(job_lookup), file)\n\n\n    def _create_job_directory(self, job_file: str, job_ctr: int) -&gt; str:\n        \"\"\"Create the job directory and symlink to the job directory.\n\n        Args:\n            job_file (str): The job file.\n            job_ctr (int): The job counter.\n        Returns:\n            str: The symlink to the job directory.\n        \"\"\"\n\n        # E.g.: job_file:\n        # /tmp/workflow-1/2024-02-05-092539/sample-5/rsync-R000989_NML05959-sample-5/rsync-R000989_NML05959-sample-5.sbatch.sh\n        job_dir = os.path.dirname(job_file)\n\n        # E.g.: job_dir:\n        # /tmp/workflow-1/2024-02-05-092539/sample-5/rsync-R000989_NML05959-sample-5\n        if not os.path.exists(job_dir):\n            pathlib.Path(job_dir).mkdir(parents=True, exist_ok=True)\n            logging.info(f\"Created directory '{job_dir}'\")\n\n        current_dir = os.getcwd()\n\n        # Create a step symlink to the job directory.\n        parent_dir = os.path.dirname(job_dir)\n        # E.g.: parent_dir:\n        # /tmp/workflow-1/2024-02-05-092539/sample-5\n\n        os.chdir(parent_dir)\n\n        job_basedir = os.path.basename(job_dir)\n        # E.g.: job_basedir:\n        # rsync-R000989_NML05959-sample-5\n\n        symlink = f\"step-{job_ctr}\"\n        # E.g.: symlink:\n        # step-1\n\n        # Create symlink to the job directory.\n        if not os.path.exists(symlink):\n            os.symlink(job_basedir, symlink)\n            # E.g.: step-1 -&gt; rsync-R000989_NML05959-sample-5\n            logging.info(f\"Created symlink '{symlink}'\")\n\n        # Return to the original directory.\n        os.chdir(current_dir)\n\n        return symlink\n\n\n    def _create_subflow_directory(self, subflow_dir: str, subflow_ctr: int) -&gt; str:\n        \"\"\"Create the subflow directory and symlink to the subflow directory.\n\n        Args:\n            subflow_dir (str): The subflow directory.\n            subflow_ctr (int): The subflow counter.\n        Returns:\n            str: The symlink to the subflow directory.\n        \"\"\"\n\n        # E.g.: subflow_dir:\n        # /tmp/workflow-1/2024-02-05-092539/sample-5\n        if not os.path.exists(subflow_dir):\n            pathlib.Path(subflow_dir).mkdir(parents=True, exist_ok=True)\n            logging.info(f\"Created subflow directory '{subflow_dir}'\")\n\n        current_dir = os.getcwd()\n\n        # Create a step symlink to the subflow directory.\n        parent_dir = os.path.dirname(subflow_dir)\n        # E.g.: parent_dir:\n        # /tmp/workflow-1/2024-02-05-092539\n\n        os.chdir(parent_dir)\n\n        subflow_basedir = os.path.basename(subflow_dir)\n        # E.g.: subflow_basedir:\n        # sample-5\n\n        symlink = f\"subflow-{subflow_ctr}\"\n        # E.g.: symlink:\n        # subflow-5\n\n        # Create symlink to the job directory.\n        if not os.path.exists(symlink):\n            os.symlink(subflow_basedir, symlink)\n            # E.g.: subflow-5 -&gt; sample-5\n            logging.info(f\"Created symlink '{symlink}'\")\n\n        # Return to the original directory.\n        os.chdir(current_dir)\n\n        return symlink\n</code></pre>"},{"location":"builder/#slurm_workflow_utils.builder.Builder.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Constructor for Builder.</p> Source code in <code>slurm_workflow_utils/builder.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Constructor for Builder.\"\"\"\n    self.control_file = kwargs.get(\"control_file\", None)\n    self.logfile = kwargs.get(\"logfile\", None)\n    self.outdir = kwargs.get(\"outdir\", None)\n    self.verbose = kwargs.get(\"verbose\", constants.DEFAULT_VERBOSE)\n\n    logging.info(f\"Will load contents of config file '{self.control_file}'\")\n    # self.control_lookup = yaml.safe_load(Path(self.control_file).read_text())\n    with open(self.control_file, \"r\") as file:\n        self.control_lookup = yaml.load(file, Loader=SafeLoader)\n\n    logging.info(f\"Instantiated Builder in file '{os.path.abspath(__file__)}'\")\n</code></pre>"},{"location":"console_helper/","title":"Console Helper module","text":""},{"location":"constants/","title":"Constants module","text":""},{"location":"file_utils/","title":"File Utils module","text":"<p>A collection of utility functions for file management and data integrity.</p> <p>Functions: - calculate_md5(file_path): Calculate the MD5 hash of a file specified by its path. - check_indir_status(indir=None): Check the status of a directory, providing information on its existence and contents. - check_infile_status(infile, extension=None): Check the status of a file, including its existence and optionally validate its extension. - get_file_creation_date(file_path): Retrieve the creation date of a file specified by its path.</p> <p>Use these functions to enhance file handling and data validation in your Python projects.</p>"},{"location":"file_utils/#slurm_workflow_utils.file_utils.calculate_md5","title":"<code>calculate_md5(file_path)</code>","text":"<p>Calculate the md5 checksum for the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>the file for which the md5 checksum will be calculated</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the calculated md5 checksum</p> Source code in <code>slurm_workflow_utils/file_utils.py</code> <pre><code>def calculate_md5(file_path: str) -&gt; str:\n    \"\"\"Calculate the md5 checksum for the specified file.\n\n    Args:\n        file_path (str): the file for which the md5 checksum will be calculated\n\n    Returns:\n        str: the calculated md5 checksum\n    \"\"\"\n    md5_hash = hashlib.md5()\n    logging.info(f\"Will attempt to calculate the MD5 checksum for file '{file_path}'\")\n\n    with open(file_path, \"rb\") as file:\n        # Read the file in chunks to efficiently handle large files\n        for chunk in iter(lambda: file.read(4096), b\"\"):\n            md5_hash.update(chunk)\n\n    return md5_hash.hexdigest()\n</code></pre>"},{"location":"file_utils/#slurm_workflow_utils.file_utils.check_indir_status","title":"<code>check_indir_status(indir=None)</code>","text":"<p>Check if the directory exists and is a regular directory.</p> <p>Parameters:</p> Name Type Description Default <code>indir</code> <code>str</code> <p>the directory to be checked</p> <code>None</code> Source code in <code>slurm_workflow_utils/file_utils.py</code> <pre><code>def check_indir_status(indir: str = None) -&gt; None:\n    \"\"\"Check if the directory exists and is a regular directory.\n\n    Args:\n        indir (str): the directory to be checked\n    \"\"\"\n    error_ctr = 0\n\n    if indir is None or indir == '':\n        error_console.print(f\"'{indir}' is not defined\")\n        error_ctr += 1\n    else:\n        if not os.path.exists(indir):\n            error_ctr += 1\n            error_console.print(f\"directory '{indir}' does not exist\")\n        else:\n            if not os.path.isdir(indir):\n                error_ctr += 1\n                error_console.print(f\"'{indir}' is not a regular directory\")\n\n    if error_ctr &gt; 0:\n        error_console.print(f\"Detected problems with input directory '{indir}'\")\n        sys.exit(1)\n</code></pre>"},{"location":"file_utils/#slurm_workflow_utils.file_utils.check_infile_status","title":"<code>check_infile_status(infile, extension=None)</code>","text":"<p>Check if the file exists, if it is a regular file and whether it has content.</p> <p>Parameters:</p> Name Type Description Default <code>infile</code> <code>str</code> <p>the file to be checked</p> required Source code in <code>slurm_workflow_utils/file_utils.py</code> <pre><code>def check_infile_status(infile: str, extension: Optional[str] = None) -&gt; None:\n    \"\"\"Check if the file exists, if it is a regular file and whether it has\n    content.\n\n    Args:\n        infile (str): the file to be checked\n\n    Raises:\n        None\n    \"\"\"\n\n    error_ctr = 0\n\n    if infile is None or infile == \"\":\n        error_console.print(f\"'{infile}' is not defined\")\n        error_ctr += 1\n    else:\n        if not os.path.exists(infile):\n            error_ctr += 1\n            error_console.print(f\"'{infile}' does not exist\")\n        else:\n            if not os.path.isfile(infile):\n                error_ctr += 1\n                error_console.print(f\"'{infile}' is not a regular file\")\n            if os.stat(infile).st_size == 0:\n                error_console.print(f\"'{infile}' has no content\")\n                error_ctr += 1\n            if extension is not None and not infile.endswith(extension):\n                error_console.print(\n                    f\"'{infile}' does not have filename extension '{extension}'\"\n                )\n                error_ctr += 1\n\n    if error_ctr &gt; 0:\n        error_console.print(f\"Detected problems with input file '{infile}'\")\n        sys.exit(1)\n</code></pre>"},{"location":"file_utils/#slurm_workflow_utils.file_utils.get_file_creation_date","title":"<code>get_file_creation_date(file_path)</code>","text":"<p>Determine the creation date for the specified file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>the absolute path of the file</p> required <p>Returns:</p> Name Type Description <code>datetime</code> <code>datetime</code> <p>the date the file was created according to the operating system</p> Source code in <code>slurm_workflow_utils/file_utils.py</code> <pre><code>def get_file_creation_date(file_path: str) -&gt; datetime:\n    \"\"\"Determine the creation date for the specified file.\n\n    Args:\n        file_path (str): the absolute path of the file\n\n    Returns:\n        datetime: the date the file was created according to the operating system\n    \"\"\"\n    if platform.system() == \"Windows\":\n        # On Windows, use creation time\n        creation_time = os.path.getctime(file_path)\n    else:\n        # On Unix-based systems, use birth time (creation time)\n        # Note: Not all file systems support birth time, and it might not be available on some systems.\n        stat_info = os.stat(file_path)\n        creation_time = stat_info.st_mtime\n\n    # Convert the timestamp to a readable date\n    creation_date = datetime.fromtimestamp(creation_time)\n\n    return creation_date\n</code></pre>"},{"location":"launcher/","title":"Launcher module","text":""},{"location":"launcher/#slurm_workflow_utils.launcher.Launcher","title":"<code>Launcher</code>","text":"<p>Class for launching SLURM sbatch shell scripts.</p> Source code in <code>slurm_workflow_utils/launcher.py</code> <pre><code>class Launcher:\n    \"\"\"Class for launching SLURM sbatch shell scripts.\"\"\"\n\n    def __init__(self, **kwargs):\n        \"\"\"Constructor for Launcher.\"\"\"\n        self.sbatch_list_file = kwargs.get(\"sbatch_list_file\", None)\n        self.logfile = kwargs.get(\"logfile\", None)\n        self.outdir = kwargs.get(\"outdir\", None)\n        self.verbose = kwargs.get(\"verbose\", constants.DEFAULT_VERBOSE)\n\n        logging.info(f\"Instantiated Builder in file '{os.path.abspath(__file__)}'\")\n\n\n    def _get_file_list_from_sbatch_list_file(self) -&gt; List[str]:\n        \"\"\"Read the sbatch list file and return the list of sbatch scripts.\n\n        Returns:\n            List[str]: The list of sbatch scripts.\n        \"\"\"\n        check_infile_status(self.sbatch_list_file)\n\n        file_list = []\n\n        with open(self.sbatch_list_file, \"r\") as file:\n            line_ctr = 0\n            for line in file:\n                line_ctr += 1\n                if line.startswith(\"#\"):\n                    continue\n                if line.strip() == \"\":\n                    continue\n                file_list.append(line.strip())\n\n        logging.info(f\"Read '{line_ctr}' lines from sbatch list file '{self.sbatch_list_file}'\")\n        return file_list\n\n\n    def launch_all(self) -&gt; None:\n        \"\"\"Launch all of the sbatch scripts in the sbatch list file.\"\"\"\n\n        file_list = self._get_file_list_from_sbatch_list_file()\n\n        ctr = 0\n\n        for sbatch_script in file_list:\n            ctr += 1\n\n            check_infile_status(sbatch_script)\n\n            if self.verbose:\n                console.log(f\"Will launch sbatch script {ctr}: '{sbatch_script}'\")\n            logging.info(f\"Will launch sbatch script {ctr}: '{sbatch_script}'\")\n\n            launch_outfile = os.path.join(\n                os.path.dirname(sbatch_script),\n                \"workflow_launcher.json\"\n            )\n\n            if os.path.exists(launch_outfile):\n                backup_file(launch_outfile)\n\n            dictionary = {\n                \"method-created\": os.path.abspath(__file__),\n                \"date-launched\":str(datetime.today().strftime('%Y-%m-%d-%H%M%S')),\n                \"sbatch-script\": os.path.realpath(sbatch_script),\n                \"created-by\": os.environ.get('USER'),\n                \"logfile\": self.logfile\n            }\n\n            with open(launch_outfile, 'w') as write_file:\n                json.dump(dictionary, write_file, indent=4, sort_keys=True)\n\n            if self.verbose:\n                console.log(f\"Wrote launch metadata file '{launch_outfile}'\")\n\n            logging.info(f\"Wrote launch metadata file '{launch_outfile}'\")\n\n\n            # os.system(f\"sbatch {sbatch_script}\")\n\n\n        logging.info(f\"Launched '{ctr}' sbatch scripts from sbatch list file '{self.sbatch_list_file}'\")\n</code></pre>"},{"location":"launcher/#slurm_workflow_utils.launcher.Launcher.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Constructor for Launcher.</p> Source code in <code>slurm_workflow_utils/launcher.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Constructor for Launcher.\"\"\"\n    self.sbatch_list_file = kwargs.get(\"sbatch_list_file\", None)\n    self.logfile = kwargs.get(\"logfile\", None)\n    self.outdir = kwargs.get(\"outdir\", None)\n    self.verbose = kwargs.get(\"verbose\", constants.DEFAULT_VERBOSE)\n\n    logging.info(f\"Instantiated Builder in file '{os.path.abspath(__file__)}'\")\n</code></pre>"},{"location":"launcher/#slurm_workflow_utils.launcher.Launcher.launch_all","title":"<code>launch_all()</code>","text":"<p>Launch all of the sbatch scripts in the sbatch list file.</p> Source code in <code>slurm_workflow_utils/launcher.py</code> <pre><code>def launch_all(self) -&gt; None:\n    \"\"\"Launch all of the sbatch scripts in the sbatch list file.\"\"\"\n\n    file_list = self._get_file_list_from_sbatch_list_file()\n\n    ctr = 0\n\n    for sbatch_script in file_list:\n        ctr += 1\n\n        check_infile_status(sbatch_script)\n\n        if self.verbose:\n            console.log(f\"Will launch sbatch script {ctr}: '{sbatch_script}'\")\n        logging.info(f\"Will launch sbatch script {ctr}: '{sbatch_script}'\")\n\n        launch_outfile = os.path.join(\n            os.path.dirname(sbatch_script),\n            \"workflow_launcher.json\"\n        )\n\n        if os.path.exists(launch_outfile):\n            backup_file(launch_outfile)\n\n        dictionary = {\n            \"method-created\": os.path.abspath(__file__),\n            \"date-launched\":str(datetime.today().strftime('%Y-%m-%d-%H%M%S')),\n            \"sbatch-script\": os.path.realpath(sbatch_script),\n            \"created-by\": os.environ.get('USER'),\n            \"logfile\": self.logfile\n        }\n\n        with open(launch_outfile, 'w') as write_file:\n            json.dump(dictionary, write_file, indent=4, sort_keys=True)\n\n        if self.verbose:\n            console.log(f\"Wrote launch metadata file '{launch_outfile}'\")\n\n        logging.info(f\"Wrote launch metadata file '{launch_outfile}'\")\n\n\n        # os.system(f\"sbatch {sbatch_script}\")\n\n\n    logging.info(f\"Launched '{ctr}' sbatch scripts from sbatch list file '{self.sbatch_list_file}'\")\n</code></pre>"},{"location":"system_caller/","title":"System Caller module","text":""},{"location":"system_caller/#slurm_workflow_utils.system_caller.execute_cmd","title":"<code>execute_cmd(cmd, outdir=None, stdout_file=None, stderr_file=None, verbose=DEFAULT_VERBOSE)</code>","text":"<p>Execute a command via system call using the subprocess module.</p> <p>Parameters:</p> Name Type Description Default <code>cmd</code> <code>str</code> <p>The executable to be invoked.</p> required <code>outdir</code> <code>str</code> <p>The output directory where STDOUT, STDERR and the shell script should be written to.</p> <code>None</code> <code>stdout_file</code> <code>str</code> <p>The file to which STDOUT will be captured in.</p> <code>None</code> <code>stderr_file</code> <code>str</code> <p>The file to which STDERR will be captured in.</p> <code>None</code> <p>Returns:     str: The path to the file where STDOUT was written to.</p> Source code in <code>slurm_workflow_utils/system_caller.py</code> <pre><code>def execute_cmd(\n    cmd: str,\n    outdir: str = None,\n    stdout_file=None,\n    stderr_file=None,\n    verbose: bool = DEFAULT_VERBOSE,\n) -&gt; str:\n    \"\"\"Execute a command via system call using the subprocess module.\n\n    Args:\n        cmd (str): The executable to be invoked.\n        outdir (str): The output directory where STDOUT, STDERR and the shell script should be written to.\n        stdout_file (str): The file to which STDOUT will be captured in.\n        stderr_file (str): The file to which STDERR will be captured in.\n    Returns:\n        str: The path to the file where STDOUT was written to.\n    \"\"\"\n    if cmd is None:\n        raise Exception(\"cmd was not specified\")\n\n    cmd = cmd.strip()\n\n    logging.info(f\"Will attempt to execute '{cmd}'\")\n    if verbose:\n        print(f\"Will attempt to execute '{cmd}'\")\n\n    if outdir is None:\n        outdir = \"/tmp\"\n        logging.info(\n            f\"outdir was not defined and therefore was set to default '{outdir}'\"\n        )\n\n    if stdout_file is None:\n        stdout_file = _derive_std_file(cmd, outdir, \"stdout\")\n\n    if stderr_file is None:\n        stderr_file = _derive_std_file(cmd, outdir, \"stderr\")\n\n\n    if os.path.exists(stdout_file):\n        logging.info(\n            f\"STDOUT file '{stdout_file}' already exists so will delete it now\"\n        )\n        os.remove(stdout_file)\n\n    if os.path.exists(stderr_file):\n        logging.info(\n            f\"STDERR file '{stderr_file}' already exists so will delete it now\"\n        )\n        os.remove(stderr_file)\n\n    consolidated_cmd = cmd\n    p = subprocess.Popen(consolidated_cmd, shell=True)\n\n    (stdout, stderr) = p.communicate()\n\n    pid = p.pid\n\n    logging.info(f\"The child process ID is '{pid}'\")\n    if verbose:\n        print(f\"The child process ID is '{pid}'\")\n\n    p_status = p.wait()\n\n    p_returncode = p.returncode\n\n    if p_returncode is not None:\n        logging.info(f\"The return code was '{p_returncode}'\")\n    else:\n        logging.info(\"There was no return code\")\n\n    if p_status == 0:\n        logging.info(f\"Execution of cmd '{cmd}' has completed\")\n    else:\n        raise Exception(f\"Received status '{p_status}'\")\n\n    if stdout is not None:\n        logging.info(\"stdout is: \" + stdout_file)\n\n    if stderr is not None:\n        logging.info(\"stderr is: \" + stderr_file)\n\n    return stdout_file\n</code></pre>"},{"location":"workflow_builder/","title":"Workflow Builder module","text":"<p>Read a YAML control file and generate all SLURM sbatchs scripts to orchestrate a workflow.</p>"},{"location":"workflow_builder/#slurm_workflow_utils.workflow_builder.main","title":"<code>main(control_file, logfile, outdir, verbose)</code>","text":"<p>Read a YAML control file and generate all SLURM sbatchs scripts to orchestrate a workflow.</p> Source code in <code>slurm_workflow_utils/workflow_builder.py</code> <pre><code>@click.command()\n@click.option('--control_file', help='Required: The YAML file that contains all of the info required to create the SLURM workflow shell scripts.')\n@click.option('--logfile', help=\"Optional: The log file\")\n@click.option('--outdir', help=f\"Optional: The default is the current working directory - default is '{DEFAULT_OUTDIR}'\")\n@click.option('--verbose', is_flag=True, help=f\"Will print more info to STDOUT - default is '{constants.DEFAULT_VERBOSE}'.\", callback=validate_verbose)\ndef main(\n    control_file: str,\n    logfile: Optional[str],\n    outdir: Optional[str],\n    verbose: Optional[bool]\n    ):\n    \"\"\"Read a YAML control file and generate all SLURM sbatchs scripts to orchestrate a workflow.\"\"\"\n    error_ctr = 0\n\n    if control_file is None:\n        print_red(\"--control_file was not specified\")\n        error_ctr += 1\n\n    if error_ctr &gt; 0:\n        print_red(\"Required parameter(s) not defined\")\n        click.echo(click.get_current_context().get_help())\n        sys.exit(1)\n\n    check_infile_status(control_file, \"yaml\")\n\n    if outdir is None:\n        outdir = DEFAULT_OUTDIR\n        print_yellow(f\"--outdir was not specified and therefore was set to '{outdir}'\")\n\n    if not os.path.exists(outdir):\n        pathlib.Path(outdir).mkdir(parents=True, exist_ok=True)\n        print_yellow(f\"Created output directory '{outdir}'\")\n\n    if logfile is None:\n        logfile = os.path.join(\n            outdir,\n            os.path.splitext(os.path.basename(__file__))[0] + '.log'\n        )\n        print_yellow(f\"--logfile was not specified and therefore was set to '{logfile}'\")\n\n    if verbose is None:\n        verbose = constants.DEFAULT_VERBOSE\n        print_yellow(f\"--verbose was not specified and therefore was set to '{verbose}'\")\n\n\n    logging.basicConfig(\n        filename=logfile,\n        format=constants.DEFAULT_LOGGING_FORMAT,\n        level=constants.DEFAULT_LOGGING_LEVEL\n    )\n\n    builder = WorkflowBuilder(\n        control_file=control_file,\n        logfile=logfile,\n        outdir=outdir,\n        verbose=verbose\n    )\n\n    builder.build()\n\n    if verbose:\n        console.print(f\"The log file is '{logfile}'.\")\n        print_green(f\"Execution of '{os.path.abspath(__file__)}' completed.\")\n</code></pre>"},{"location":"workflow_builder/#slurm_workflow_utils.workflow_builder.validate_verbose","title":"<code>validate_verbose(ctx, param, value)</code>","text":"<p>Validate the validate option.</p> <p>Parameters:</p> Name Type Description Default <code>ctx</code> <code>Context</code> <p>The click context.</p> required <code>param</code> <code>str</code> <p>The parameter.</p> required <code>value</code> <code>bool</code> <p>The value.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>The value.</p> Source code in <code>slurm_workflow_utils/workflow_builder.py</code> <pre><code>def validate_verbose(ctx, param, value):\n    \"\"\"Validate the validate option.\n\n    Args:\n        ctx (Context): The click context.\n        param (str): The parameter.\n        value (bool): The value.\n\n    Returns:\n        bool: The value.\n    \"\"\"\n\n    if value is None:\n        click.secho(\"--verbose was not specified and therefore was set to 'True'\", fg='yellow')\n        return constants.DEFAULT_VERBOSE\n    return value\n</code></pre>"},{"location":"workflow_launcher/","title":"Workflow Launcher module","text":"<p>Read the sbatch_scripts.txt and perform sbatch submit for each sbatch script.</p>"},{"location":"workflow_launcher/#slurm_workflow_utils.workflow_launcher.main","title":"<code>main(infile, logfile, outdir, verbose)</code>","text":"<p>Read the sbatch_scripts.txt and perform sbatch submit for each sbatch script.</p> Source code in <code>slurm_workflow_utils/workflow_launcher.py</code> <pre><code>@click.command()\n@click.option('--infile', help='Required: The sbatch_script.txt file that contains the list of sbatch scripts to be launched via the sbatch command.')\n@click.option('--logfile', help=\"Optional: The log file\")\n@click.option('--outdir', help=f\"Optional: The default is the current working directory - default is '{DEFAULT_OUTDIR}'\")\n@click.option('--verbose', is_flag=True, help=f\"Will print more info to STDOUT - default is '{constants.DEFAULT_VERBOSE}'.\", callback=validate_verbose)\ndef main(\n    infile: str,\n    logfile: Optional[str],\n    outdir: Optional[str],\n    verbose: Optional[bool]\n    ):\n    \"\"\"Read the sbatch_scripts.txt and perform sbatch submit for each sbatch script.\"\"\"\n    error_ctr = 0\n\n    if infile is None:\n        print_red(\"--infile was not specified\")\n        error_ctr += 1\n\n    if error_ctr &gt; 0:\n        print_red(\"Required parameter(s) not defined\")\n        click.echo(click.get_current_context().get_help())\n        sys.exit(1)\n\n    check_infile_status(infile, \"txt\")\n\n    if outdir is None:\n        outdir = DEFAULT_OUTDIR\n        print_yellow(f\"--outdir was not specified and therefore was set to '{outdir}'\")\n\n    if not os.path.exists(outdir):\n        pathlib.Path(outdir).mkdir(parents=True, exist_ok=True)\n        print_yellow(f\"Created output directory '{outdir}'\")\n\n    if logfile is None:\n        logfile = os.path.join(\n            outdir,\n            os.path.splitext(os.path.basename(__file__))[0] + '.log'\n        )\n        print_yellow(f\"--logfile was not specified and therefore was set to '{logfile}'\")\n\n    if verbose is None:\n        verbose = constants.DEFAULT_VERBOSE\n        print_yellow(f\"--verbose was not specified and therefore was set to '{verbose}'\")\n\n\n    logging.basicConfig(\n        filename=logfile,\n        format=constants.DEFAULT_LOGGING_FORMAT,\n        level=constants.DEFAULT_LOGGING_LEVEL\n    )\n\n    launcher = WorkflowLauncher(\n        sbatch_list_file=infile,\n        logfile=logfile,\n        outdir=outdir,\n        verbose=verbose\n    )\n\n    launcher.launch_all()\n\n    if verbose:\n        console.print(f\"The log file is '{logfile}'.\")\n        print_green(f\"Execution of '{os.path.abspath(__file__)}' completed.\")\n</code></pre>"},{"location":"workflow_launcher/#slurm_workflow_utils.workflow_launcher.validate_verbose","title":"<code>validate_verbose(ctx, param, value)</code>","text":"<p>Validate the validate option.</p> <p>Parameters:</p> Name Type Description Default <code>ctx</code> <code>Context</code> <p>The click context.</p> required <code>param</code> <code>str</code> <p>The parameter.</p> required <code>value</code> <code>bool</code> <p>The value.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>The value.</p> Source code in <code>slurm_workflow_utils/workflow_launcher.py</code> <pre><code>def validate_verbose(ctx, param, value):\n    \"\"\"Validate the validate option.\n\n    Args:\n        ctx (Context): The click context.\n        param (str): The parameter.\n        value (bool): The value.\n\n    Returns:\n        bool: The value.\n    \"\"\"\n\n    if value is None:\n        click.secho(\"--verbose was not specified and therefore was set to 'True'\", fg='yellow')\n        return constants.DEFAULT_VERBOSE\n    return value\n</code></pre>"}]}